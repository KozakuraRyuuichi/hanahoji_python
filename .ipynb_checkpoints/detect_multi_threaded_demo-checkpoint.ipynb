{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import detector_utils as detector_utils\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import multiprocessing\n",
    "from multiprocessing import Queue, Pool\n",
    "import time\n",
    "from utils.detector_utils import WebcamVideoStream\n",
    "import datetime\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_processed = 0\n",
    "score_thresh = 0.2\n",
    "\n",
    "def worker(input_q, output_q, cap_params, frame_processed):\n",
    "    print(\">> loading frozen model for worker\")\n",
    "    detection_graph, sess = detector_utils.load_inference_graph()\n",
    "    sess = tf.Session(graph=detection_graph)\n",
    "    while True:\n",
    "        #print(\"> ===== in worker loop, frame \", frame_processed)\n",
    "        frame = input_q.get()\n",
    "        if (frame is not None):\n",
    "            # Actual detection. Variable boxes contains the bounding box cordinates for hands detected,\n",
    "            # while scores contains the confidence for each of these boxes.\n",
    "            # Hint: If len(boxes) > 1 , you may assume you have found atleast one hand (within your score threshold)\n",
    "\n",
    "            boxes, scores = detector_utils.detect_objects(\n",
    "                frame, detection_graph, sess)\n",
    "            # draw bounding boxes\n",
    "            detector_utils.draw_box_on_image(\n",
    "                cap_params['num_hands_detect'], cap_params[\"score_thresh\"],\n",
    "                scores, boxes, cap_params['im_width'], cap_params['im_height'],\n",
    "                frame)\n",
    "            # add frame annotated with bounding box to queue\n",
    "            output_q.put(frame)\n",
    "            frame_processed += 1\n",
    "        else:\n",
    "            output_q.put(frame)\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'im_width': 640.0, 'im_height': 480.0, 'score_thresh': 0.2, 'num_hands_detect': 2} Namespace(display=1, fps=1, height=200, num_hands=2, num_workers=4, queue_size=5, video_source=0, width=300)\n",
      ">> loading frozen model for worker\n",
      ">> loading frozen model for worker> ====== loading HAND frozen graph into memory\n",
      "\n",
      ">> loading frozen model for worker> ====== loading HAND frozen graph into memory\n",
      "\n",
      ">> loading frozen model for worker> ====== loading HAND frozen graph into memory\n",
      "\n",
      "> ====== loading HAND frozen graph into memory\n",
      ">  ====== Hand Inference graph loaded.>  ====== Hand Inference graph loaded.>  ====== Hand Inference graph loaded.\n",
      "\n",
      ">  ====== Hand Inference graph loaded.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        '-src',\n",
    "        '--source',\n",
    "        dest='video_source',\n",
    "        type=int,\n",
    "        default=0,\n",
    "        help='Device index of the camera.')\n",
    "    parser.add_argument(\n",
    "        '-nhands',\n",
    "        '--num_hands',\n",
    "        dest='num_hands',\n",
    "        type=int,\n",
    "        default=2,\n",
    "        help='Max number of hands to detect.')\n",
    "    parser.add_argument(\n",
    "        '-fps',\n",
    "        '--fps',\n",
    "        dest='fps',\n",
    "        type=int,\n",
    "        default=1,\n",
    "        help='Show FPS on detection/display visualization')\n",
    "    parser.add_argument(\n",
    "        '-wd',\n",
    "        '--width',\n",
    "        dest='width',\n",
    "        type=int,\n",
    "        default=300,\n",
    "        help='Width of the frames in the video stream.')\n",
    "    parser.add_argument(\n",
    "        '-ht',\n",
    "        '--height',\n",
    "        dest='height',\n",
    "        type=int,\n",
    "        default=200,\n",
    "        help='Height of the frames in the video stream.')\n",
    "    parser.add_argument(\n",
    "        '-ds',\n",
    "        '--display',\n",
    "        dest='display',\n",
    "        type=int,\n",
    "        default=1,\n",
    "        help='Display the detected images using OpenCV. This reduces FPS')\n",
    "    parser.add_argument(\n",
    "        '-num-w',\n",
    "        '--num-workers',\n",
    "        dest='num_workers',\n",
    "        type=int,\n",
    "        default=4,\n",
    "        help='Number of workers.')\n",
    "    parser.add_argument(\n",
    "        '-q-size',\n",
    "        '--queue-size',\n",
    "        dest='queue_size',\n",
    "        type=int,\n",
    "        default=5,\n",
    "        help='Size of the queue.')\n",
    "    args = parser.parse_args(args=[])\n",
    "\n",
    "    input_q = Queue(maxsize=args.queue_size)\n",
    "    output_q = Queue(maxsize=args.queue_size)\n",
    "\n",
    "    video_capture = WebcamVideoStream(\n",
    "        src=args.video_source, width=args.width, height=args.height).start()\n",
    "\n",
    "    cap_params = {}\n",
    "    frame_processed = 0\n",
    "    cap_params['im_width'], cap_params['im_height'] = video_capture.size()\n",
    "    cap_params['score_thresh'] = score_thresh\n",
    "\n",
    "    # max number of hands we want to detect/track\n",
    "    cap_params['num_hands_detect'] = args.num_hands\n",
    "\n",
    "    print(cap_params, args)\n",
    "\n",
    "    # spin up workers to paralleize detection.\n",
    "    pool = Pool(args.num_workers, worker,\n",
    "                (input_q, output_q, cap_params, frame_processed))\n",
    "\n",
    "    start_time = datetime.datetime.now()\n",
    "    num_frames = 0\n",
    "    fps = 0\n",
    "    index = 0\n",
    "\n",
    "    cv2.namedWindow('Multi-Threaded Detection', cv2.WINDOW_NORMAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    while True:\n",
    "        frame = video_capture.read()\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        index += 1\n",
    "\n",
    "#         input_q.put(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        output_frame = output_q.get()\n",
    "\n",
    "        output_frame = cv2.cvtColor(output_frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        elapsed_time = (datetime.datetime.now() - start_time).total_seconds()\n",
    "        num_frames += 1\n",
    "        fps = num_frames / elapsed_time\n",
    "        # print(\"frame \",  index, num_frames, elapsed_time, fps)\n",
    "\n",
    "        if (output_frame is not None):\n",
    "            if (args.display > 0):\n",
    "                if (args.fps > 0):\n",
    "                    detector_utils.draw_fps_on_image(\"FPS : \" + str(int(fps)),\n",
    "                                                     output_frame)\n",
    "                cv2.imshow('Multi-Threaded Detection', output_frame)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            else:\n",
    "                if (num_frames == 400):\n",
    "                    num_frames = 0\n",
    "                    start_time = datetime.datetime.now()\n",
    "                else:\n",
    "                    print(\"frames processed: \", index, \"elapsed time: \",\n",
    "                          elapsed_time, \"fps: \", str(int(fps)))\n",
    "        else:\n",
    "            # print(\"video end\")\n",
    "            break\n",
    "    elapsed_time = (datetime.datetime.now() - start_time).total_seconds()\n",
    "    fps = num_frames / elapsed_time\n",
    "    print(\"fps\", fps)\n",
    "    pool.terminate()\n",
    "    video_capture.stop()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
