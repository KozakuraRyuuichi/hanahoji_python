{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import detector_utils as detector_utils\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import argparse\n",
    "import easydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> ====== loading HAND frozen graph into memory\n",
      ">  ====== Hand Inference graph loaded.\n"
     ]
    }
   ],
   "source": [
    "detection_graph, sess = detector_utils.load_inference_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        '-sth',\n",
    "        '--scorethreshold',\n",
    "        dest='score_thresh',\n",
    "        type=float,\n",
    "        default=0.2,\n",
    "        help='Score threshold for displaying bounding boxes')\n",
    "    parser.add_argument(\n",
    "        '-fps',\n",
    "        '--fps',\n",
    "        dest='fps',\n",
    "        type=int,\n",
    "        default=1,\n",
    "        help='Show FPS on detection/display visualization')\n",
    "    parser.add_argument(\n",
    "        '-src',\n",
    "        '--source',\n",
    "        dest='video_source',\n",
    "        default=0,\n",
    "        help='Device index of the camera.')\n",
    "    parser.add_argument(\n",
    "        '-wd',\n",
    "        '--width',\n",
    "        dest='width',\n",
    "        type=int,\n",
    "        default=320,\n",
    "        help='Width of the frames in the video stream.')\n",
    "    parser.add_argument(\n",
    "        '-ht',\n",
    "        '--height',\n",
    "        dest='height',\n",
    "        type=int,\n",
    "        default=180,\n",
    "        help='Height of the frames in the video stream.')\n",
    "    parser.add_argument(\n",
    "        '-ds',\n",
    "        '--display',\n",
    "        dest='display',\n",
    "        type=int,\n",
    "        default=1,\n",
    "        help='Display the detected images using OpenCV. This reduces FPS')\n",
    "    parser.add_argument(\n",
    "        '-num-w',\n",
    "        '--num-workers',\n",
    "        dest='num_workers',\n",
    "        type=int,\n",
    "        default=4,\n",
    "        help='Number of workers.')\n",
    "    parser.add_argument(\n",
    "        '-q-size',\n",
    "        '--queue-size',\n",
    "        dest='queue_size',\n",
    "        type=int,\n",
    "        default=5,\n",
    "        help='Size of the queue.')\n",
    "    args = parser.parse_args(args=[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "    cap = cv2.VideoCapture(1)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, args.width)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, args.height)\n",
    "\n",
    "    start_time = datetime.datetime.now()\n",
    "    num_frames = 0\n",
    "    im_width, im_height = (cap.get(3), cap.get(4))\n",
    "    # max number of hands we want to detect/track\n",
    "    num_hands_detect = 2\n",
    "\n",
    "#     cv2.namedWindow('Single-Threaded Detection', cv2.WINDOW_NORMAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting to RGB\n"
     ]
    }
   ],
   "source": [
    "# Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "ret, image_np = cap.read()\n",
    "# image_np = cv2.flip(image_np, 1)\n",
    "try:\n",
    "    image_np = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)\n",
    "except:\n",
    "    print(\"Error converting to RGB\")\n",
    "\n",
    "# Actual detection. Variable boxes contains the bounding box cordinates for hands detected,\n",
    "# while scores contains the confidence for each of these boxes.\n",
    "# Hint: If len(boxes) > 1 , you may assume you have found atleast one hand (within your score threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
