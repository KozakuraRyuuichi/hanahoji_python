{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from src.hand_tracker import HandTracker\n",
    "import datetime\n",
    "\n",
    "from slacker import Slacker\n",
    " \n",
    "# Slack通知\n",
    "def slacker():\n",
    "    # APIトークンを指定\n",
    "    token = 'xoxb-1416141106465-1389788588327-nK5jk6j2zjCU43KO5blbDIyB'\n",
    "    # アップロードするチャンネルを指定\n",
    "    channel = \"#\" + \"random\"\n",
    "    # 絶対パスを指定\n",
    "    file = '/Users/kozakuraryuuichi/hanahoji/outputs/demo.jpg'\n",
    " \n",
    "    slacker = Slacker(token)\n",
    "    slacker.files.upload(file_=file, channels=channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 鼻検知\n",
    "# カスケードファイルの読み込み\n",
    "cascade_path =  \"OpenCV-detection-models-master/haarcascades/haarcascade_mcs_nose.xml\"\n",
    "cascade = cv2.CascadeClassifier(cascade_path)\n",
    "# 囲み線の色を緑に設定\n",
    "rectangle_color = (0, 255, 0)  \n",
    "\n",
    "# 指検知\n",
    "# 宿題：何を読み込んでるのか理解必要\n",
    "window = \"Hand Tracking\"\n",
    "palm_model_path = \"models/palm_detection_without_custom_op.tflite\"\n",
    "landmark_model_path = \"models/hand_landmark.tflite\"\n",
    "anchors_path = \"models/anchors.csv\"\n",
    "\n",
    "# 投影の色を設定\n",
    "point_color = (0, 255, 0)\n",
    "connection_color = (255, 0, 0)\n",
    "thickness = 2\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "# カメラの読み込み\n",
    "# cap = cv2.VideoCapture(0)\n",
    "file = \"demo_4fps.mp4\"\n",
    "filepath = \"./inputs/\" + file\n",
    "cap = cv2.VideoCapture(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "else:\n",
    "    ret = False\n",
    "    \n",
    "#        8   12  16  20\n",
    "#        |   |   |   |\n",
    "#        7   11  15  19\n",
    "#    4   |   |   |   |\n",
    "#    |   6   10  14  18\n",
    "#    3   |   |   |   |\n",
    "#    |   5---9---13--17\n",
    "#    2    \\         /\n",
    "#     \\    \\       /\n",
    "#      1    \\     /\n",
    "#       \\    \\   /\n",
    "#        ------0-\n",
    "    \n",
    "# 指の投影ポイントに番号を割り振る\n",
    "# タプルにしてみた\n",
    "connections = (\n",
    "    (0, 1), (1, 2), (2, 3), (3, 4),\n",
    "    (5, 6), (6, 7), (7, 8),\n",
    "    (9, 10), (10, 11), (11, 12),\n",
    "    (13, 14), (14, 15), (15, 16),\n",
    "    (17, 18), (18, 19), (19, 20),\n",
    "    (0, 5), (5, 9), (9, 13), (13, 17), (0, 17)\n",
    ")\n",
    "\n",
    "# 手の検知器を設定    \n",
    "detector = HandTracker(\n",
    "    palm_model_path,\n",
    "    landmark_model_path,\n",
    "    anchors_path,\n",
    "    box_shift=0.2,\n",
    "    box_enlarge=1.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No hands found\n",
      "No hands found\n",
      "No hands found\n",
      "No hands found\n",
      "No hands found\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    # フレームの読み取り\n",
    "    ret, frame = cap.read()\n",
    "    # フレーム読めなかったら終了    \n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # 精度向上のためinput画像を白黒化\n",
    "    nose_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    noses = cascade.detectMultiScale(nose_gray, scaleFactor=1.3, minNeighbors=10, minSize=(30, 30))\n",
    "\n",
    "    #　鼻の検知\n",
    "    if len(noses) > 0:\n",
    "        for nose in noses:\n",
    "            # 鼻の中心座標を求める\n",
    "            center = nose[0:2] + nose[2:4] / 2\n",
    "            x_cen = center[0]\n",
    "            y_cen = center[1]\n",
    "#             cv2.circle(frame, (int(x_cen), int(y_cen)), thickness, point_color, thickness)\n",
    "#             cv2.putText(frame, 'FPS: {:.2f}'.format(fps), (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), thickness=2)\n",
    "            \n",
    "            # detectorメソッドがRGB読み込みのため変換\n",
    "            hand_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            points, _ = detector(hand_image)\n",
    "            if points is not  None:\n",
    "#                 cv2.circle(frame, (int(x_cen), int(y_cen)), thickness, point_color, thickness)\n",
    "                for point in points:\n",
    "                    # 人差し指と小指について先端と第1関節の距離をそれぞれ取得\n",
    "                    indexFinger_length = np.linalg.norm(points[7] - points[8])\n",
    "                    littleFinger_length = np.linalg.norm(points[19] - points[20])\n",
    "                    #　指先端から鼻中心の距離\n",
    "                    indexFinger_nose_dist = np.linalg.norm(center- points[8])\n",
    "                    littleFinger_nose_dist = np.linalg.norm(center- points[20])\n",
    "                    # 上記で求めた距離の比\n",
    "                    indexFinger_ratio =  indexFinger_nose_dist / indexFinger_length\n",
    "                    littleFinger_ratio =  littleFinger_nose_dist / littleFinger_length\n",
    "\n",
    "                    # 鼻と指の検知描画はしない（処理重くなるから）\n",
    "                    # 比が1を下回ったらほじったと認定\n",
    "                    if indexFinger_ratio < 1 or littleFinger_ratio < 1:\n",
    "                        cv2.putText(frame, \"oh my God!!!!\", (int(x_cen), int(y_cen)), font, 1,(0, 0, 255), 3, cv2.LINE_AA)\n",
    "#                         dt_now = datetime.datetime.now()\n",
    "#                         outname = dt_now.strftime('%y%m%d%H%M%S')\n",
    "                        output_path = \"./outputs/\" + \"demo\" + \".jpg\"\n",
    "                        cv2.imwrite(output_path, frame)\n",
    "                        slacker()\n",
    "            \n",
    "    # 描画\n",
    "    cv2.imshow('frame',frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# # 終了処理\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 終了処理\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
